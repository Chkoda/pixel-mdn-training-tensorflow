{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed Density Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import h5py\n",
    "import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import genconfig\n",
    "from train_MDN import train_nn, mixture_density_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import yaml\n",
    "Option = namedtuple(\"MyStruct\", \"training_input training_output validation_fraction outFile network_type \\\n",
    "                    config structure learning_rate regularizer epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Particle Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Config file, options are : 'number','pos1','pos2','pos3', 'error1x', 'error1y', 'error2x', 'error2y', 'error3x', 'error3y'  \n",
    "Below is example of pos2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python genconfig.py --type pos2 > pos2config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with generated config run train_nn which stores training history in text file in training_output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Option(\n",
    "    training_input='NNinput_pos2_training.h5',\n",
    "    training_output='Trained',\n",
    "    validation_fraction=0.1,\n",
    "    outFile='pos2',\n",
    "    network_type='2particle',\n",
    "    config='pos2config.json',\n",
    "    structure=[100, 80, 50],\n",
    "    learning_rate=0.0001,\n",
    "    regularizer=0.0001,\n",
    "    epochs=1,\n",
    ")\n",
    "\n",
    "print('loading config from: ', options.config)\n",
    "config = open(options.config, 'r')\n",
    "yamlConfig = yaml.load(config, Loader=yaml.FullLoader)\n",
    "yamlConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2, history_2 = train_nn(\n",
    "                        options.training_input,\n",
    "                        options.training_output,\n",
    "                        options.validation_fraction,\n",
    "                        options.outFile,\n",
    "                        options.network_type,\n",
    "                        options.config,\n",
    "                        options.structure,\n",
    "                        options.learning_rate,\n",
    "                        options.regularizer,\n",
    "                        options.epochs,\n",
    "                        #args.momentum,\n",
    "                        #args.batch,\n",
    "                        ##args.min_epochs,\n",
    "                        #args.max_epochs,\n",
    "                        ##args.patience_increase,\n",
    "                        ##args.threshold,\n",
    "                        #args.min_delta,\n",
    "                        #args.patience,\n",
    "                        #args.profile,\n",
    "                        #args.nbworkers,\n",
    "                        #args.save_all,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_output = 'Trained'\n",
    "outFile = 'pos2'\n",
    "output_location = training_output+'/'+outFile+'_'+datetime.datetime.now().strftime('%m_%d_%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save(output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(output_location, custom_objects={'abs' : tf.keras.backend.abs,\n",
    "                                                                        'loss' : mixture_density_loss(nb_components=1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow 2.x features method model.save() which creates model file that stores both the weights and architecture. Loading the model from this format requires only custom objects like the above activation and loss functions to be provided. That means it includes the config, optimizer, and weights of the model. Older Tensorflow/keras model saving format required saving a weights .h5 file as well as the config and rebuilding the model and its architecture from that, which still requires the custom objects as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve Two Particle Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = np.loadtxt('Trained/pos2_06_04_0556_training_pos2.txt')\n",
    "validation_loss = np.loadtxt('Trained/pos2_06_04_0556_validation_pos2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(train_loss, val_loss, fileName, outputDir):\n",
    "    plt.figure(figsize=(7,5))\n",
    "    \n",
    "    plt.plot(train_loss, color='b', linewidth=0.5)\n",
    "    plt.plot(val_loss, color='r', linewidth=0.5)\n",
    "    plt.title('Model Loss over Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.xlim(0,250)\n",
    "    plt.ylim(0, 0.9)\n",
    "    plt.legend(['training set','validation set'])\n",
    "    plt.savefig(outputDir+'/'+fileName+'_Loss.pdf')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(training_loss, validation_loss, 'pos2', 'Trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Particle Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python genconfig.py --type pos1 > pos1config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Option(\n",
    "    training_input='NNinput_pos1_training.h5',\n",
    "    training_output='Trained',\n",
    "    validation_fraction=0.1,\n",
    "    outFile='pos1',\n",
    "    network_type='1particle',\n",
    "    config='pos1config.json',\n",
    "    structure=[100, 50, 50],\n",
    "    learning_rate=0.0001,\n",
    "    regularizer=0.0001,\n",
    "    epochs=250,\n",
    ")\n",
    "\n",
    "print('loading config from: ', options.config)\n",
    "config = open(options.config, 'r')\n",
    "yamlConfig = yaml.load(config, Loader=yaml.FullLoader)\n",
    "yamlConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1, history_1 = train_nn(\n",
    "                        options.training_input,\n",
    "                        options.training_output,\n",
    "                        options.validation_fraction,\n",
    "                        options.outFile,\n",
    "                        options.network_type,\n",
    "                        options.config,\n",
    "                        options.structure,\n",
    "                        options.learning_rate,\n",
    "                        options.regularizer,\n",
    "                        options.epochs,\n",
    "                        #args.momentum,\n",
    "                        #args.batch,\n",
    "                        ##args.min_epochs,\n",
    "                        #args.max_epochs,\n",
    "                        ##args.patience_increase,\n",
    "                        ##args.threshold,\n",
    "                        #args.min_delta,\n",
    "                        #args.patience,\n",
    "                        #args.profile,\n",
    "                        #args.nbworkers,\n",
    "                        #args.save_all,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three Particle Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python genconfig.py --type pos3 > pos3config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Option(\n",
    "    training_input='NNinput_pos3_training.h5',\n",
    "    training_output='Trained',\n",
    "    validation_fraction=0.1,\n",
    "    outFile='pos3',\n",
    "    network_type='3particle',\n",
    "    config='pos3config.json',\n",
    "    structure=[100, 80, 50],\n",
    "    learning_rate=0.0001,\n",
    "    regularizer=0.0001,\n",
    "    epochs=250,\n",
    ")\n",
    "\n",
    "print('loading config from: ', options.config)\n",
    "config = open(options.config, 'r')\n",
    "yamlConfig = yaml.load(config, Loader=yaml.FullLoader)\n",
    "yamlConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3, history_3 = train_nn(\n",
    "                        options.training_input,\n",
    "                        options.training_output,\n",
    "                        options.validation_fraction,\n",
    "                        options.outFile,\n",
    "                        options.network_type,\n",
    "                        options.config,\n",
    "                        options.structure,\n",
    "                        options.learning_rate,\n",
    "                        options.regularizer,\n",
    "                        options.epochs,\n",
    "                        #args.momentum,\n",
    "                        #args.batch,\n",
    "                        ##args.min_epochs,\n",
    "                        #args.max_epochs,\n",
    "                        ##args.patience_increase,\n",
    "                        ##args.threshold,\n",
    "                        #args.min_delta,\n",
    "                        #args.patience,\n",
    "                        #args.profile,\n",
    "                        #args.nbworkers,\n",
    "                        #args.save_all,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2p = tf.keras.models.load_model('Trained/pos2_06_04_0556', custom_objects={'abs' : tf.keras.backend.abs,\n",
    "                                                                        'loss' : mixture_density_loss(nb_components=1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('NNinput_pos3_training.h5', 'r') as hf:  \n",
    "    #x_train = hf['train_data_x'][:]\n",
    "    #y_train = hf['train_data_y'][:]\n",
    "    x_valid = hf['valid_data_x'][:]\n",
    "    y_valid = hf['valid_data_y'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branches = utils.get_data_config_names('pos2config.json', meta=False)\n",
    "print(branches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_3.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean = np.hstack((y_pred[0][:,1:3], y_pred[1][:,1:3], y_pred[2][:,1:3]))\n",
    "pred_prec = np.hstack((y_pred[0][:,3:5], y_pred[1][:,3:5], y_pred[2][:,3:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean - y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean = np.hstack((y_pred[0][:,1:3], y_pred[1][:,1:3]))\n",
    "pred_mean[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prec = np.hstack((y_pred[0][:,3:5], y_pred[1][:,3:5]))\n",
    "pred_prec[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(y_pred[0][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1 = tf.reshape(x_valid[0], [1,60])\n",
    "x_test_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = model_2p.predict(x_test_1)\n",
    "y_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
